{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Symbolic Learning\n",
    "Ruchi Gupte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import asarray,save,load\n",
    "from numpy.lib.stride_tricks import as_strided\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import MeanShift\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "import idx2numpy\n",
    "import pickle\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import json\n",
    "import math\n",
    "import glob\n",
    "import random\n",
    "import sklearn\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"training_image_path\"             : \"Jio_imagepath/FASHION_MNIST/train-images-idx3-ubyte\", \n",
    "          \"load_path\"                       : \"_5x5_FashMNIST_Kmeans\", \n",
    "          \"test_image_path\"                 : \"Jio_imagepath/FASHION_MNIST/t10k-images-idx3-ubyte\", \n",
    "          \"genral_path_incase_of_folder\"    : \"Jio_imagepath/New\", \n",
    "          \"dataset_format\"                  : \"ubyte\", \n",
    "          \"sampleimages\"                    : 1000, \n",
    "          \"window_size\"                     : 5, \n",
    "          \"Stride\"                          : 3, \n",
    "          \"padding\"                         : [0, 1, 0, 1], \n",
    "          \"image_size\"                      : 28, \n",
    "          \"clustering_model\"                : \"KMEANS\", \n",
    "          \"n_clusters\"                      : 150, \n",
    "          \"bandwidth\"                       : 300, \n",
    "          \"test_skip\"                       : 2, \n",
    "          \"Consistency_formula\"             : \"NPMI\", \n",
    "          \"model_load\"                      : 0, \n",
    "          \"neighbor_range\"                  : 2, }\n",
    "with open('config.json', 'w') as f:\n",
    "        json.dump(config, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage 0 : Read Stage\n",
    "Taking input as config.json file, take test images and load them and store them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#INPUT----------------------------------\n",
    "with open('config.json', 'r') as f:\n",
    "        config = json.load(f)\n",
    "load_path=config['load_path']\n",
    "padding=config['padding'] #Padding per image incase of uneven strides\n",
    "no_of_sampleimages=config['sampleimages']\n",
    "type_dataset=config['dataset_format']  #The path and file type of dataset\n",
    "#INPUT----------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 training images and 10000 test images added\n"
     ]
    }
   ],
   "source": [
    "if type_dataset=='folder': #Incase dataset is a set of images in a folder\n",
    "    final_image_list = []\n",
    "    for img in glob.glob(config['genral_path_incase_of_folder']+'/*.jpg*'):\n",
    "        temp_image= cv2.imread(img,0)\n",
    "        final_image_list.append(temp_image)\n",
    "    #random.shuffle(final_image_list) #Incase you want to shuffle dataset\n",
    "    testdata, traindata = sklearn.model_selection.train_test_split(final_image_list, train_size=0.4, test_size=0.6)\n",
    "\n",
    "elif type_dataset=='ubyte': #In case of MNIS, images are stored in ubyte folder\n",
    "    traindata = idx2numpy.convert_from_file(config['training_image_path']) \n",
    "    testdata = idx2numpy.convert_from_file(config['test_image_path']) \n",
    "    \n",
    "else:\n",
    "    print(\"Error in Reading Images in Stage 0\")\n",
    "print(str(len(traindata))+\" training images and \"+str(len(testdata))+\" test images added\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x18b780a9f08>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAQT0lEQVR4nO3dfWxd9X3H8c/Xju0Q58FxQoIbWIA2E2RdG5hLyoAKhkA01RpaASqaqkxCSieBClr/GOv+KP+sQ9Not2pVtTAQ6cboqlEU/ojWQtQV2EaKyUIeGmhSCBBi8kAgcR78eL/7w4fJDT7fY+65T+vv/ZKsa9/vPfd8feyPz/X9nXN+5u4C8JuvrdkNAGgMwg4kgrADiSDsQCIIO5CIWY1cWad1+Wx1N3KVQFKGdUqjPmLT1UqF3cxukvR3ktol/aO73x89fra6tdquL7NKAIGtviW3VvXLeDNrl/RdSZ+VtFLS7Wa2strnA1BfZf5nv0LSPnd/1d1HJf1A0tratAWg1sqEfZmkN6d8fSC779eY2XozGzCzgTGNlFgdgDLKhH26NwE+cOytu29w93537+9QV4nVASijTNgPSLpgytfnSzpYrh0A9VIm7C9IWmFmF5lZp6QvSXqyNm0BqLWqh97cfdzM7pL0Y00OvT3s7rtr1hmAmio1zu7umyVtrlEvAOqIw2WBRBB2IBGEHUgEYQcSQdiBRBB2IBGEHUgEYQcSQdiBRBB2IBGEHUgEYQcSQdiBRBB2IBGEHUgEYQcSQdiBRBB2IBGEHUgEYQcSQdiBRBB2IBGEHUgEYQcSQdiBRBB2IBGEHUgEYQcSQdiBRBB2IBGlpmw2s/2ShiRNSBp39/5aNAWg9kqFPXOdux+twfMAqCNexgOJKBt2l/QTM3vRzNZP9wAzW29mA2Y2MKaRkqsDUK2yL+OvcveDZrZE0lNm9rK7PzP1Ae6+QdIGSZpvvV5yfQCqVGrP7u4Hs9vDkp6QdEUtmgJQe1WH3cy6zWze+59LulHSrlo1BqC2yryMXyrpCTN7/3n+xd3/vSZdAai5qsPu7q9K+mQNewFQRwy9AYkg7EAiCDuQCMIOJIKwA4kg7EAiCDuQCMIOJIKwA4kg7EAiCDuQCMIOJIKwA4moxQUnUW+TpxEH9eBvdmWitr3U0Jm18bVOztn08wZ10lraexaE9Yn3jlf1vOzZgUQQdiARhB1IBGEHEkHYgUQQdiARhB1IBOPs/x94wUQ6Xr+x9L2P/F5YX74sntPz4PMfya2tuGZ/uGzl5Y+F9YlX9oX1MqyjM6z72Gip59//l1fm1m5e89/hsjv/YGFuzY6359bYswOJIOxAIgg7kAjCDiSCsAOJIOxAIgg7kAjG2WuhLX9sU5LklYJ6wTh6CW2fuCSs/9WmjWH9i89cHtbf3NEX1jsm8s/Ff+O9nnDZRX9/Oqx33hCWSyk7jn7oq78f1m/93LO5tYu6joTLDlyef+xDZWtXbq1wz25mD5vZYTPbNeW+XjN7ysz2Zrf5o/wAWsJMXsY/Iumms+67V9IWd18haUv2NYAWVhh2d39G0rGz7l4r6f3Xfxsl3VzjvgDUWLVv0C1190FJym6X5D3QzNab2YCZDYxppMrVASir7u/Gu/sGd+939/4O5b95AKC+qg37ITPrk6Ts9nDtWgJQD9WG/UlJ67LP10naVJt2ANRL4Ti7mT0m6VpJi83sgKRvSLpf0g/N7A5Jb0i6tZ5NzkjRtdWLxrLLLF/y2uxts2eHdbvogrD+zc3/nFu75fFPh8ve9tg9YX3pzni7nbgw3l+Mz8lf/swr8Tj7smsGw/qf74/P+/7io3+aW7vo306Ey7aNjof1wesWhfVr18XXvD8z0ZFbe/C1q8NlF732Tm4t6rsw7O5+e07p+qJlAbQODpcFEkHYgUQQdiARhB1IBGEHEmFex9Mrzzbfen21/ea9iT/8h/HUw0WW3bs3rO86cl5Y79qUP4TlBX/OTy2LhxzHFhScnltg4pxg+YLRzs6j8anDfavjobk/Wf6z3No7E3PDZd8YiYfWLpvzelj/8bsfD+v/se3S3NqVn4x/H47dvSy39vzuf9CJUwen3bLs2YFEEHYgEYQdSARhBxJB2IFEEHYgEYQdSASXks60rVoZ1kcXnZNbO3DbWLjs6ov3h/U3H/jtsH5Od/w3+fR5+QPW43PCRVWZFR9n0TYSD4YXjeO3teU/oDI7HsOvxLMm6/im/OmgJembXXknbEpDK+JTWM+7MP80Ukl6zi4O6+/9LD42oic4w/bz128Pl904vDS3ZsGPkz07kAjCDiSCsAOJIOxAIgg7kAjCDiSCsAOJaOw4+5zZskt+J7e874/mhYvPPpr/t2miYLKZsbnxeLJ3xPXOd/PX3fNsvOyu/8k/d1mShj8VL28Fp5R3DAXLxsPJsoLZpkcXxpfJnrPkVFjv6T6TW1vQNRwuO78zri/ujNf99nD+79O2V38rXPa95/PHsiWp872wrErBvMZdn8ufV2XH6fjS4ccuy3/y8YP5P1D27EAiCDuQCMIOJIKwA4kg7EAiCDuQCMIOJKKh4+wj57bplTvzzwtffekvw+VPjMZTG0fGKvGA8qGh+Dripxbnr3tsfjzI33U0Pid81sm4fmZ5fL58x6Wnc2ufWBpfW/1j3UfC+tKOeGrjc2fF9TltI2E9cqzg2u6HxhaE9c2786/d/vnffSlc9m9vGAjrIx7/TL7z7iVhvRJcCGC4kj+dsyQtfPlkbq39TP5BGYV7djN72MwOm9muKffdZ2Zvmdn27GNN0fMAaK6ZvIx/RNJN09z/bXdflX1srm1bAGqtMOzu/oykYw3oBUAdlXmD7i4z25G9zM89WNfM1pvZgJkNTJyMj2UGUD/Vhv17kj4qaZWkQUkP5D3Q3Te4e7+797fP7a5ydQDKqirs7n7I3SfcvSLpQUnlpjEFUHdVhd3M+qZ8+QVJu/IeC6A1FM7PbmaPSbpW0mJJhyR9I/t6lSSXtF/SV9w9HtCVNK/nfL/s6q/m1g9cFw/727L8c6MX9eSPPUrSku64PmfWaFg/eDJ/THd+wXnZg0PxefrXfmRfWF/WFZ88fTq4wHrRmO2rpxaH9Xkd8ff29CvxeHLPs/nHJwwvio8vuHRNfNzF0DVHw3oZ7Yt6w7rNi48BKOLH8y9C4Gfyf88lqW1hT27tv478q46PHp52wxYeVOPu011p/6Gi5QC0Fg6XBRJB2IFEEHYgEYQdSARhBxJROPRWSws6lviVvbfkP6AnHqKa+NXrVa/bOuKBh7aCo/vGVi7PrZ3ui09xPXhjfD3nvqfj3hb+/O2wXjmYX68Mx0Nnrax9RTwt8rv9S8J679Zgu1UKrs89Hl9C20/GQ7myeD9qC/J/1ycWFuRgbv5Q6wvbvqsTQ29NO/TGnh1IBGEHEkHYgUQQdiARhB1IBGEHEkHYgUQ09FLSPj6uiSP5ly5u740vDXzylk/l1ioF30nbWHw8wexj8Vh45/Mv59Y6PrMyXPaS78RjspUd+c8tSZXZ8SW07fy+/FpPuasDTXTHp8iOzSnY8MFZrG3j8c+k/bX40oezRuLl374hf7uc+2Iwz7WkSmd86XEbj0+B9fZ4Pzo+L3+7js6L133O4fh07Dzs2YFEEHYgEYQdSARhBxJB2IFEEHYgEYQdSERDz2efb72+2q5v2PqmalsVj4VPdOefI1xkaHk8Dj77nXgMf3hRPFY93hVfcrnrRP652e2jBZcKr8T1jpNx7+2n4qmLKx3BmHFb/H1NdMXjze3DcW+jC/N/pl1H4vP8Pepb0uiC+PiDIp3H87db+6l4HL3y0p7c2tbK0zrhxzifHUgZYQcSQdiBRBB2IBGEHUgEYQcSQdiBRDT0fPZmqmz/RViPR3xj8/+zxMKSqh/hb76iozTKbNeyv5zx1fxjRX2Xee4iBVe0r1rhnt3MLjCzn5rZHjPbbWZ3Z/f3mtlTZrY3u11Ypx4B1MBMXsaPS/qau18q6dOS7jSzlZLulbTF3VdI2pJ9DaBFFYbd3QfdfVv2+ZCkPZKWSVoraWP2sI2Sbq5XkwDK+1Bv0JnZhZIuk7RV0lJ3H5Qm/yBImnbiLTNbb2YDZjYwppFy3QKo2ozDbmZzJT0u6R53PzHT5dx9g7v3u3t/R13f1gAQmVHYzaxDk0F/1N1/lN19yMz6snqfpMP1aRFALczk3XiT9JCkPe7+rSmlJyWtyz5fJ2lT7dsDUCszGcq8StKXJe00s+3ZfV+XdL+kH5rZHZLekHRrfVoEUAuFYXf355R/jEFzrkQB4EPjcFkgEYQdSARhBxJB2IFEEHYgEYQdSARhBxJB2IFEEHYgEYQdSARhBxJB2IFEEHYgEYQdSARhBxJB2IFEEHYgEYQdSARhBxJB2IFEEHYgEYQdSARhBxJB2IFEEHYgEYQdSARhBxJB2IFEEHYgETOZn/0CM/upme0xs91mdnd2/31m9paZbc8+1tS/XQDVmsn87OOSvubu28xsnqQXzeyprPZtd/+b+rUHoFZmMj/7oKTB7PMhM9sjaVm9GwNQWx/qf3Yzu1DSZZK2ZnfdZWY7zOxhM1uYs8x6Mxsws4ExjZRqFkD1Zhx2M5sr6XFJ97j7CUnfk/RRSas0ued/YLrl3H2Du/e7e3+HumrQMoBqzCjsZtahyaA/6u4/kiR3P+TuE+5ekfSgpCvq1yaAsmbybrxJekjSHnf/1pT7+6Y87AuSdtW+PQC1MpN346+S9GVJO81se3bf1yXdbmarJLmk/ZK+UpcOAdTETN6Nf06STVPaXPt2ANQLR9ABiSDsQCIIO5AIwg4kgrADiSDsQCIIO5AIwg4kgrADiSDsQCIIO5AIwg4kgrADiSDsQCLM3Ru3MrMjkl6fctdiSUcb1sCH06q9tWpfEr1Vq5a9LXf3c6crNDTsH1i52YC79zetgUCr9taqfUn0Vq1G9cbLeCARhB1IRLPDvqHJ64+0am+t2pdEb9VqSG9N/Z8dQOM0e88OoEEIO5CIpoTdzG4ys1fMbJ+Z3duMHvKY2X4z25lNQz3Q5F4eNrPDZrZryn29ZvaUme3NbqedY69JvbXENN7BNONN3XbNnv684f+zm1m7pF9KukHSAUkvSLrd3X/R0EZymNl+Sf3u3vQDMMzsM5JOSvq+u388u++vJR1z9/uzP5QL3f3PWqS3+ySdbPY03tlsRX1TpxmXdLOkP1YTt13Q121qwHZrxp79Ckn73P1Vdx+V9ANJa5vQR8tz92ckHTvr7rWSNmafb9TkL0vD5fTWEtx90N23ZZ8PSXp/mvGmbrugr4ZoRtiXSXpzytcH1Frzvbukn5jZi2a2vtnNTGOpuw9Kk788kpY0uZ+zFU7j3UhnTTPeMtuumunPy2pG2KebSqqVxv+ucvfLJX1W0p3Zy1XMzIym8W6UaaYZbwnVTn9eVjPCfkDSBVO+Pl/SwSb0MS13P5jdHpb0hFpvKupD78+gm90ebnI//6eVpvGebppxtcC2a+b0580I+wuSVpjZRWbWKelLkp5sQh8fYGbd2RsnMrNuSTeq9aaiflLSuuzzdZI2NbGXX9Mq03jnTTOuJm+7pk9/7u4N/5C0RpPvyP9K0l80o4ecvi6W9FL2sbvZvUl6TJMv68Y0+YroDkmLJG2RtDe77W2h3v5J0k5JOzQZrL4m9Xa1Jv813CFpe/axptnbLuirIduNw2WBRHAEHZAIwg4kgrADiSDsQCIIO5AIwg4kgrADifhfflfV2ej/Q+8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(testdata[9])  #show patch in dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindata = traindata[:no_of_sampleimages]\n",
    "testdata = testdata[:no_of_sampleimages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Padding\n",
    "final_train_data=[0]*no_of_sampleimages #Inserting padding to each image\n",
    "for k in range(no_of_sampleimages):\n",
    "    final_train_data[k]=np.pad(traindata[k], [(padding[0], padding[1]), (padding[2], padding[3])], mode='constant', constant_values=0)\n",
    "        \n",
    "final_test_data=[0]*no_of_sampleimages  #Inserting padding to each image\n",
    "for k in range(no_of_sampleimages):\n",
    "    final_test_data[k]=np.pad(traindata[k], [(padding[0], padding[1]), (padding[2], padding[3])], mode='constant', constant_values=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage 0 Completed Succesfully!\n"
     ]
    }
   ],
   "source": [
    "#OUTPUT-------------------------------------------\n",
    "np.save('Array_of_training_images'+load_path+'temp.npy', final_train_data)  #Remove temp for final\n",
    "np.save('Array_of_test_images'+load_path+'temp.npy', final_test_data)\n",
    "print(\"Stage 0 Completed Succesfully!\")\n",
    "#OUTPUT-------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage 1 :Low Level Feature extraction\n",
    "Taking input as config.json and training data, convert data into patches and store them and store them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#INPUT----------------------------------\n",
    "with open('config.json', 'r') as f:\n",
    "        config = json.load(f)\n",
    "load_path=config['load_path']\n",
    "widthi=heighti=config['image_size'] #Height and width of input image\n",
    "no_of_sampleimages=config['sampleimages']\n",
    "patch_size=config['window_size'] #Size of patches to consider\n",
    "shift=config['Stride']  #Stride for each patch\n",
    "padding=config['padding']\n",
    "data = np.load('Array_of_training_images'+load_path+'.npy')\n",
    "#INPUT----------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_im=[]\n",
    "for k in range(no_of_sampleimages):\n",
    "    patchl=0\n",
    "    patchh=0\n",
    "    image=data[k]\n",
    "    for i in range(0,heighti+padding[0]+padding[1]-(patch_size-1),shift):\n",
    "        for j in range(0,widthi+padding[2]+padding[3]-(patch_size-1),shift):\n",
    "            BLOCK=image[i:i+patch_size,j:j+patch_size]\n",
    "            X_im.append(BLOCK) \n",
    "            patchl=patchl+1\n",
    "        patchh=patchh+1\n",
    "        \n",
    "patchl=int(patchl/patchh)\n",
    "X_im = np.array(X_im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81000"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "imageno=153 #Select which image in dataset\n",
    "patchno=patchl*patchh\n",
    "image=X_im[patchno*imageno:patchno*(imageno+1)]\n",
    "BLUE = [255,255,255]\n",
    "size = 100, 100\n",
    "\n",
    "new_im = Image.new('RGBA', (patchh*100, patchl*100), (255, 255, 255, 255))\n",
    "k=0\n",
    "for i in range(0,patchh*100,100):\n",
    "    for j in range(0,patchl*100,100):\n",
    "        im=cv2.copyMakeBorder(image[k],0,1,0,1,cv2.BORDER_CONSTANT,value=BLUE)\n",
    "        ima = Image.fromarray(im, 'L')\n",
    "        im = ima.resize((100,100), resample=Image.NEAREST)\n",
    "        k=k+1\n",
    "        new_im.paste(im, (j,i))\n",
    "               \n",
    "new_im.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage 1 Completed Succesfully!\n"
     ]
    }
   ],
   "source": [
    "#OUTPUT-------------------------------------------\n",
    "config.update( {'patchl' : patchl, # Adding patch length to config\n",
    "                'patchh' : patchh} ) #Adding patch height to config\n",
    "with open('config.json', 'w') as f:\n",
    "        json.dump(config, f)\n",
    "np.save('patchlist'+load_path+'temp.npy', X_im) #Remove temp for final\n",
    "print(\"Stage 1 Completed Succesfully!\")\n",
    "#OUTPUT-------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage 2: Symbolic ID Creation\n",
    "Taking input as config.json and data of image patches, perform clustering on them and gather data like centroids, distances and assign each patch to a appropriate cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#INPUT----------------------------------\n",
    "with open('config.json', 'r') as f:\n",
    "        config = json.load(f)\n",
    "load_path=config['load_path']\n",
    "patchlist = np.load('patchlist'+load_path+'.npy')\n",
    "patch_size=config['window_size']\n",
    "#INPUT---------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "stage2_load_condition=1   # 1 to load from pre existing model and 0 for new training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from file....\n",
      "Loaded\n"
     ]
    }
   ],
   "source": [
    "if stage2_load_condition==1:\n",
    "    print(\"Loading model from file....\")\n",
    "    model = pickle.load(open('model'+load_path+'.sav', 'rb'))\n",
    "    n_clusters=config['n_clusters']\n",
    "    labels=model.labels_\n",
    "    centroids = model.cluster_centers_\n",
    "    print(\"Loaded\")\n",
    "        \n",
    "else:\n",
    "    if config['clustering_model']=='KMEANS':\n",
    "        time_start = time.time()\n",
    "        n_clusters=config['n_clusters']\n",
    "        model = KMeans(n_clusters=n_clusters, n_init=10, max_iter=300, tol=1e-4, verbose=0, random_state=None, copy_x=True, algorithm=\"auto\")\n",
    "        model=model.fit(patchlist.reshape(len(patchlist),-1))\n",
    "        labels=model.labels_\n",
    "        centroids = model.cluster_centers_\n",
    "        print(\"Kmeans Done. Time elapsed: {} minutes\".format((time.time()-time_start)/60))\n",
    "        print(time.time()-time_start)\n",
    "        \n",
    "    elif config['clustering_model']=='MEANSHIFT':\n",
    "        time_start = time.time()\n",
    "        bandwidth=config['bandwidth']\n",
    "        model = MeanShift(bandwidth=bandwidth, bin_seeding=False, cluster_all=True, min_bin_freq=1, n_jobs=1, seeds= None)\n",
    "        model=model.fit(patchlist.reshape(len(patchlist),-1))\n",
    "        labels = model.labels_\n",
    "        centroids = model.cluster_centers_\n",
    "        labels_unique = np.unique(labels)\n",
    "        n_clusters = len(labels_unique)\n",
    "        config.update( {'n_clusters' : n_clusters} )\n",
    "        print (\"MeanShift Done. Time elapsed: {} minutes\".format((time.time()-time_start)/60))\n",
    "        print(time.time()-time_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'algorithm': 'auto',\n",
       " 'copy_x': True,\n",
       " 'init': 'k-means++',\n",
       " 'max_iter': 300,\n",
       " 'n_clusters': 150,\n",
       " 'n_init': 10,\n",
       " 'n_jobs': 'deprecated',\n",
       " 'precompute_distances': 'deprecated',\n",
       " 'random_state': None,\n",
       " 'tol': 0.0001,\n",
       " 'verbose': 0}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_params() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Sort(sub_li): \n",
    "    sub_li.sort(key = lambda x: x[1]) \n",
    "    return sub_li "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=0\n",
    "clusterdata=[]\n",
    "for clus in range(n_clusters):\n",
    "    for i in patchlist[np.where(labels==clus)]:\n",
    "        k=k+1\n",
    "    temp=[clus+1,k]\n",
    "    clusterdata.append(temp)   \n",
    "    k=0 #comment to check cumulative density \n",
    "clusterdata=Sort(clusterdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i in range(n_clusters, 0, -1):\n",
    "    #print(clusterdata[i-1][0],'   :  ', clusterdata[i-1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp=[]\n",
    "clustack=[]\n",
    "for clus in range(n_clusters):\n",
    "    for i in patchlist[np.where(labels==clus)]:\n",
    "        temp.append(i)\n",
    "    clustack.append(np.array(temp))\n",
    "    temp=[]\n",
    "clustack=np.array(clustack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist=[]\n",
    "for Clusterno in range(n_clusters):\n",
    "    temp=[]\n",
    "    Cent=centroids[Clusterno].reshape(patch_size,patch_size)\n",
    "    k=0\n",
    "    for m in clustack[Clusterno]:\n",
    "        distance = np.linalg.norm(m-Cent)\n",
    "        distance=[int(k),int(distance)]\n",
    "        temp.append(distance)\n",
    "        k=k+1\n",
    "    dist.append(temp)\n",
    "for clus in range(n_clusters):\n",
    "    dist[clus]=np.array(Sort(dist[clus]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_no=18 # cluster number\n",
    "\n",
    "Rows=10  #how many rows and columns in collage\n",
    "Columns=10\n",
    "Background_white = [255,255,255]\n",
    "final_collage = Image.new('RGBA', (1000, 1000), (255, 255,255))\n",
    "k=0\n",
    "\n",
    "for i in range(0,Columns*100,100):\n",
    "    for j in range(0,Rows*100,100):\n",
    "        temp_image=cv2.copyMakeBorder(clustack[cluster_no-1][int(dist[cluster_no-1][k][0])],0,1,0,1,cv2.BORDER_CONSTANT,value=Background_white)\n",
    "        temp_image = Image.fromarray(temp_image, 'L')\n",
    "        temp_image = temp_image.resize((100,100), resample=Image.NEAREST)\n",
    "        k=k+1\n",
    "        final_collage.paste(temp_image, (j,i))\n",
    "\n",
    "final_collage.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#OUTPUT------------------------ Remove temp for final-------------\n",
    "np.save('cluster_density'+load_path+'temp.npy', clusterdata)\n",
    "np.save('patch_with_clusters'+load_path+'temp.npy', clustack)\n",
    "np.save('distance_info_for_clusters'+load_path+'temp.npy', dist)\n",
    "pickle.dump(model, open('model'+load_path+'temp.sav', 'wb'))\n",
    "print(\"Stage 2 Completed Succesfully!\")\n",
    "#OUTPUT-----------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage 3 : Symbolic ID Assignment\n",
    "Taking input as config.json, model, its parameters, and test data, convert them to a symbolic matrix using the model from the training images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#INPUT----------------------------------------------------\n",
    "with open('config.json', 'r') as f:\n",
    "        config = json.load(f)\n",
    "load_path=config['load_path']\n",
    "model = pickle.load(open('model'+load_path+'.sav', 'rb'))\n",
    "test_data=np.load('Array_of_test_images'+load_path+'.npy',allow_pickle = True )\n",
    "#INPUT-----------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "centroids = model.cluster_centers_\n",
    "no_of_sampleimages=config['sampleimages']\n",
    "widthi=heighti=config['image_size']\n",
    "padding=config['padding']\n",
    "patch_size=config['window_size']\n",
    "shift=config['Stride']\n",
    "patchl=config['patchl']\n",
    "patchh=config['patchh']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "stage3_load_condition=1 # 1 to load from pre existing model and 0 for new training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading existing symbolic list....\n",
      "Loaded\n"
     ]
    }
   ],
   "source": [
    "if stage3_load_condition==1:\n",
    "    print(\"Loading existing symbolic list....\")\n",
    "    test_symboliclist=np.load('testdata_symboliclist'+load_path+'.npy')\n",
    "    print(\"Loaded\")\n",
    "    \n",
    "else:\n",
    "    test_symboliclist=[]\n",
    "    time_start = time.time()\n",
    "    for testno in range(no_of_sampleimages):\n",
    "        X_reconstructed=[]\n",
    "        print(testno)\n",
    "        image=test_data[testno]  #to select an image number\n",
    "        for i in range(0,heighti+padding[0]+padding[1]-(patch_size-1),shift):\n",
    "            for j in range(0,widthi+padding[2]+padding[3]-(patch_size-1),shift):\n",
    "                BLOCK=image[i:i+patch_size,j:j+patch_size]\n",
    "                v=model.predict(BLOCK.reshape(1, -1))\n",
    "                X_reconstructed.append(v[0]+1)\n",
    "        test_symboliclist.append(X_reconstructed)\n",
    "    print(\"Symbolic List Created. Time elapsed: {} minutes\".format((time.time()-time_start)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "for testno in range(no_of_sampleimages):\n",
    "    test_symboliclist[testno]=np.array(test_symboliclist[testno])\n",
    "    test_symboliclist[testno]=test_symboliclist[testno].reshape(patchl,patchh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  2,  73, 110,  26,  26, 129,  88,  37, 107],\n",
       "       [ 71,  46, 103,   3,   3,   3, 108,  13,  54],\n",
       "       [111, 119,  60, 135, 135, 135, 145,  60, 148],\n",
       "       [139,  96, 108, 129,  26,  26, 136,  96, 126],\n",
       "       [  2,   2,  43,  18,  18,  18, 121,  89,   2],\n",
       "       [  2,   2,  43,  18,  18,  18, 121,  89,   2],\n",
       "       [  2,   2,  43,  18,  18,  18, 121,  89,   2],\n",
       "       [  2,   2,  43,  18,  18,  18, 121,  89,   2],\n",
       "       [  2,   2,  31,   6,   6,   6,  28,  16,   2]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_symboliclist[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_reconstructed=test_symboliclist[6].reshape(patchl*patchh,)\n",
    "\n",
    "Background_white = [255,255,255]\n",
    "\n",
    "final_image = Image.new('RGBA', (1000, 1000), (255, 255, 255, 255))\n",
    "\n",
    "k=0\n",
    "for i in range(0,patchh*100,100):\n",
    "    for j in range(0,patchl*100,100):\n",
    "        Centroid=centroids[X_reconstructed[k]-1].reshape(patch_size,patch_size)\n",
    "        temp_image=cv2.copyMakeBorder(Centroid,0,1,0,1,cv2.BORDER_CONSTANT,value=Background_white)\n",
    "        temp_image = Image.fromarray(temp_image)\n",
    "        temp_image = temp_image.resize((100,100), resample=Image.NEAREST)\n",
    "        k=k+1\n",
    "        final_image.paste(temp_image, (j,i))\n",
    "               \n",
    "final_image.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#OUTPUT-----------------------------Remove temp for final---------------\n",
    "np.save('testdata_symboliclist'+load_path+'temp.npy', test_symboliclist)\n",
    "print(\"Stage 3 Completed Succesfully!\")\n",
    "#OUTPUT-----------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage 4: Hardcoding directional matrix\n",
    "Since the position of matrix elements remains same across same size images, obtain directional matrix values of each element wrt all other elements in that matrix. Input as config.json."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#INPUT-----------------------------------------\n",
    "with open('config.json', 'r') as f:\n",
    "        config = json.load(f)\n",
    "load_path=config['load_path']\n",
    "model = pickle.load(open('model'+load_path+'.sav', 'rb'))\n",
    "no_of_sampleimages=config['sampleimages']\n",
    "test_skip=config[\"test_skip\"]\n",
    "symbolic_list=np.load('testdata_symboliclist'+load_path+'.npy')\n",
    "patchlength=config['patchl']\n",
    "patchheight=config['patchh']\n",
    "patch_size=config['window_size']\n",
    "neighbor_range=config['neighbor_range']\n",
    "centroids = model.cluster_centers_\n",
    "#INPUT-----------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos2(x): \n",
    "    ans=math.cos(x)*math.cos(x)\n",
    "    return ans\n",
    "\n",
    "def sin2(x): \n",
    "    ans=math.sin(x)*math.sin(x)\n",
    "    return ans\n",
    "\n",
    "def sliding_window(arr, window_size):\n",
    "    \"\"\" Construct a sliding window view of the array\"\"\"\n",
    "    arr = np.asarray(arr)\n",
    "    window_size = int(window_size)\n",
    "    if arr.ndim != 2:\n",
    "        raise ValueError(\"need 2-D input\")\n",
    "    if not (window_size > 0):\n",
    "        raise ValueError(\"need a positive window size\")\n",
    "    shape = (arr.shape[0] - window_size + 1,\n",
    "             arr.shape[1] - window_size + 1,\n",
    "             window_size, window_size)\n",
    "    if shape[0] <= 0:\n",
    "        shape = (1, shape[1], arr.shape[0], shape[3])\n",
    "    if shape[1] <= 0:\n",
    "        shape = (shape[0], 1, shape[2], arr.shape[1])\n",
    "    strides = (arr.shape[1]*arr.itemsize, arr.itemsize,\n",
    "               arr.shape[1]*arr.itemsize, arr.itemsize)\n",
    "    return as_strided(arr, shape=shape, strides=strides)\n",
    "\n",
    "def cell_neighbors(arr, i, j, d):\n",
    "    \"\"\"Return d-th neighbors of cell (i, j)\"\"\"\n",
    "    w = sliding_window(arr, 2*d+1)\n",
    "\n",
    "    ix = np.clip(i - d, 0, w.shape[0]-1)\n",
    "    jx = np.clip(j - d, 0, w.shape[1]-1)\n",
    "\n",
    "    i0 = max(0, i - d - ix)\n",
    "    j0 = max(0, j - d - jx)\n",
    "    i1 = w.shape[2] - max(0, d - i + ix)\n",
    "    j1 = w.shape[3] - max(0, d - j + jx)\n",
    "\n",
    "    return w[ix, jx][i0:i1,j0:j1].ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  2,  73, 110,  26,  26, 129,  88,  37, 107],\n",
       "       [ 71,  46, 103,   3,   3,   3, 108,  13,  54],\n",
       "       [111, 119,  60, 135, 135, 135, 145,  60, 148],\n",
       "       [139,  96, 108, 129,  26,  26, 136,  96, 126],\n",
       "       [  2,   2,  43,  18,  18,  18, 121,  89,   2],\n",
       "       [  2,   2,  43,  18,  18,  18, 121,  89,   2],\n",
       "       [  2,   2,  43,  18,  18,  18, 121,  89,   2],\n",
       "       [  2,   2,  43,  18,  18,  18, 121,  89,   2],\n",
       "       [  2,   2,  31,   6,   6,   6,  28,  16,   2]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "symbolic_list[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  2, 110,  26,  88, 107],\n",
       "       [111,  60, 135, 145, 148],\n",
       "       [  2,  43,  18, 121,   2],\n",
       "       [  2,  43,  18, 121,   2],\n",
       "       [  2,  31,   6,  28,   2]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_images=[]\n",
    "image=[]\n",
    "for num in range(no_of_sampleimages):\n",
    "    image=symbolic_list[num]\n",
    "    patchl=0\n",
    "    patchh=0\n",
    "    temp=[]\n",
    "    for i in range(0,patchheight,test_skip):\n",
    "        for j in range(0,patchlength,test_skip):\n",
    "            temp.append(image[i][j])\n",
    "            patchl=patchl+1\n",
    "        patchh=patchh+1\n",
    "    \n",
    "    patchl=int(patchl/patchh)\n",
    "    temp=np.array(temp)\n",
    "    temp=temp.reshape(patchh,patchl)\n",
    "    test_images.append(temp)\n",
    "test_images[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_reconstructed=test_images[1].reshape(patchl*patchh,)\n",
    "#X_reconstructed=test_images[1].reshape(patchl*patchh,)\n",
    "Background_white = [255,255,255]\n",
    "\n",
    "final_image = Image.new('RGBA', (1000, 1000), (255, 255, 255, 255))\n",
    "\n",
    "k=0\n",
    "for i in range(0,patchh*100,100):\n",
    "    for j in range(0,patchl*100,100):\n",
    "        Centroid=centroids[X_reconstructed[k]-1].reshape(patch_size,patch_size)\n",
    "        temp_image=cv2.copyMakeBorder(Centroid,0,0,0,0,cv2.BORDER_CONSTANT,value=Background_white)\n",
    "        temp_image = Image.fromarray(temp_image)\n",
    "        temp_image = temp_image.resize((100,100), resample=Image.NEAREST)\n",
    "        k=k+1\n",
    "        final_image.paste(temp_image, (j,i))\n",
    "               \n",
    "final_image.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  1,  2,  3,  4],\n",
       "       [ 5,  6,  7,  8,  9],\n",
       "       [10, 11, 12, 13, 14],\n",
       "       [15, 16, 17, 18, 19],\n",
       "       [20, 21, 22, 23, 24]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arrayorder=[]\n",
    "k=0\n",
    "for y2 in range(patchh):\n",
    "    for x2 in range(patchl):\n",
    "        arrayorder.append(k)\n",
    "        k=k+1\n",
    "arrayorder=np.array(arrayorder)\n",
    "arrayorder=arrayorder.reshape(patchh,patchl)\n",
    "arrayorder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make patchh,patchl 5 if we change the dimension of input matrix\n",
    "weights=[]\n",
    "for y1 in range(patchh):\n",
    "    for x1 in range(patchl):\n",
    "        temp=[]\n",
    "        for y2 in range(patchh):\n",
    "            for x2 in range(patchl):\n",
    "                if y2>y1 and x1==x2:\n",
    "                    x=90 #pure north\n",
    "                elif y2<y1 and x1==x2:\n",
    "                    x=-90 #pure south\n",
    "                elif y2==y1 and x2==x1:\n",
    "                    x=0\n",
    "                elif x1>x2 and y1==y2:\n",
    "                    x=404   #pure west\n",
    "                elif x2>x1 and y1==y2:\n",
    "                    x=303  #pure east\n",
    "                else:\n",
    "                    slope = ((y2-y1)/(x2-x1))\n",
    "                    x=math.atan(slope)\n",
    "                temp.append([int(x1),int(y1),int(x2),int(y2),x])\n",
    "        weights.append(temp)\n",
    "#getting angles for each element[point1,point2==>angle]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "values=[]\n",
    "l=0\n",
    "for y1 in range(patchh):\n",
    "    for x1 in range(patchl):\n",
    "        k=0\n",
    "        element=[]\n",
    "        for y2 in range(patchh):\n",
    "            for x2 in range(patchl):\n",
    "                angle=weights[l][k][4] #radians\n",
    "                if angle==90:\n",
    "                    ans=[1,0,0,0] #north\n",
    "                elif angle==-90:\n",
    "                    ans=[0,1,0,0] #south\n",
    "                elif angle==404:\n",
    "                    ans=[0,0,1,0] #east\n",
    "                elif angle==303:\n",
    "                    ans=[0,0,0,1] #west\n",
    "                elif x1==x2 and y1==y2:\n",
    "                    ans=[0,0,0,0] #samepoint       \n",
    "                elif x1>x2 and y1>y2:\n",
    "                    ans=[0,sin2(angle),0,cos2(angle)] #southwest\n",
    "                elif x1>x2 and y1<y2:\n",
    "                    ans=[sin2(angle),0,0,cos2(angle)] #northwest\n",
    "                elif x1<x2 and y1>y2:\n",
    "                    ans=[0,sin2(angle),cos2(angle),0] #southeast\n",
    "                elif x1<x2 and y1<y2:\n",
    "                    ans=[sin2(angle),0,cos2(angle),0] #northeast\n",
    "                else:\n",
    "                    ans=4040404 #error\n",
    "                element.append([x1,y1,x2,y2,ans]) #all relations for one point\n",
    "                k=k+1 #increment to next point\n",
    "        #print(4040404 in element[4])\n",
    "        values.append(element)  \n",
    "        l=l+1 #increment to next pivot point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 0, 0, 0, [0, 0, 1, 0]],\n",
       " [1, 0, 1, 0, [0, 0, 0, 0]],\n",
       " [1, 0, 2, 0, [0, 0, 0, 1]],\n",
       " [1, 0, 3, 0, [0, 0, 0, 1]],\n",
       " [1, 0, 4, 0, [0, 0, 0, 1]],\n",
       " [1, 0, 0, 1, [0.5000000000000001, 0, 0, 0.5000000000000001]],\n",
       " [1, 0, 1, 1, [1, 0, 0, 0]],\n",
       " [1, 0, 2, 1, [0.5000000000000001, 0, 0.5000000000000001, 0]],\n",
       " [1, 0, 3, 1, [0.19999999999999998, 0, 0.7999999999999999, 0]],\n",
       " [1, 0, 4, 1, [0.1, 0, 0.8999999999999999, 0]],\n",
       " [1, 0, 0, 2, [0.7999999999999999, 0, 0, 0.2000000000000001]],\n",
       " [1, 0, 1, 2, [1, 0, 0, 0]],\n",
       " [1, 0, 2, 2, [0.7999999999999999, 0, 0.2000000000000001, 0]],\n",
       " [1, 0, 3, 2, [0.5000000000000001, 0, 0.5000000000000001, 0]],\n",
       " [1, 0, 4, 2, [0.3076923076923076, 0, 0.6923076923076924, 0]],\n",
       " [1, 0, 0, 3, [0.8999999999999999, 0, 0, 0.1]],\n",
       " [1, 0, 1, 3, [1, 0, 0, 0]],\n",
       " [1, 0, 2, 3, [0.8999999999999999, 0, 0.1, 0]],\n",
       " [1, 0, 3, 3, [0.6923076923076922, 0, 0.3076923076923077, 0]],\n",
       " [1, 0, 4, 3, [0.5000000000000001, 0, 0.5000000000000001, 0]],\n",
       " [1, 0, 0, 4, [0.9411764705882353, 0, 0, 0.05882352941176466]],\n",
       " [1, 0, 1, 4, [1, 0, 0, 0]],\n",
       " [1, 0, 2, 4, [0.9411764705882353, 0, 0.05882352941176466, 0]],\n",
       " [1, 0, 3, 4, [0.7999999999999999, 0, 0.2000000000000001, 0]],\n",
       " [1, 0, 4, 4, [0.6399999999999999, 0, 0.3600000000000001, 0]]]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values[1]#x1,y1,x2,y2,directionalmatrix for those 2 positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "if neighbor_range!=\"NA\":\n",
    "    final=[]\n",
    "    c=0\n",
    "    for y1 in range(patchh):\n",
    "        for x1 in range(patchl):\n",
    "            ans=cell_neighbors(arrayorder,y1,x1,neighbor_range)\n",
    "            standby=[]\n",
    "            for i in range(len(ans)):\n",
    "                standby.append(values[c][ans[i]])\n",
    "            final.append(standby) #final gives only those points within neighbor distance\n",
    "            c=c+1\n",
    "else:\n",
    "    final=values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage 4 Completed Succesfully!\n"
     ]
    }
   ],
   "source": [
    "#OUTPUT---------------------------------------Remove temp for final---------------\n",
    "np.save('AllHardcoded_directionalmatrix'+load_path+'temp.npy', values)\n",
    "np.save('New_symbolic_list'+load_path+'temp.npy', test_images)\n",
    "np.save('Selected_Hardcoded_directionalmatrix'+load_path+'temp.npy', final)\n",
    "config.update( {'stage4_patchl' : patchl,\n",
    "                'stage4_patchh' : patchh} )\n",
    "with open('config.json', 'w') as f:\n",
    "        json.dump(config, f)\n",
    "print(\"Stage 4 Completed Succesfully!\")\n",
    "#OUTPUT---------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage 5: Patch to Patch Co-Occurence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#INPUT------------------------------------------------------------------------\n",
    "with open('config.json', 'r') as f:\n",
    "        config = json.load(f)\n",
    "load_path=config['load_path']\n",
    "new_symbolic_list=np.load('New_symbolic_list'+load_path+'.npy')\n",
    "final=np.load('Selected_Hardcoded_directionalmatrix'+load_path+'.npy',allow_pickle = True )\n",
    "formula=config['Consistency_formula']\n",
    "#INPUT------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Co Occurrence Tables Created. Time elapsed: 3.1014020442962646 seconds\n"
     ]
    }
   ],
   "source": [
    "time_start = time.time()\n",
    "north_table = []\n",
    "south_table=[]\n",
    "east_table=[]\n",
    "west_table=[]\n",
    "for num in range(1000):\n",
    "    trial=new_symbolic_list[num]\n",
    "    for poi in range(len(final)):\n",
    "        for ele in range(len(final[poi])):\n",
    "            data=final[poi][ele]\n",
    "            a_id=trial[data[1]][data[0]]\n",
    "            b_id=trial[data[3]][data[2]]\n",
    "            dictionary_data_north = {'a_id': a_id, 'b_id' : b_id, 'count_north': data[4][0]}\n",
    "            dictionary_data_south= {'a_id': a_id, 'b_id' : b_id, 'count_south': data[4][1]}\n",
    "            dictionary_data_east= {'a_id': a_id, 'b_id' : b_id, 'count_east': data[4][2]}\n",
    "            dictionary_data_west= {'a_id': a_id, 'b_id' : b_id, 'count_west': data[4][3]}          \n",
    "            north_table.append(dictionary_data_north)\n",
    "            south_table.append(dictionary_data_south)\n",
    "            east_table.append(dictionary_data_east)\n",
    "            west_table.append(dictionary_data_west)\n",
    "                \n",
    "north_table = pd.DataFrame.from_dict(north_table)\n",
    "north_table = north_table[(north_table[['count_north']] != 0).all(axis=1)]\n",
    "north_table = pd.pivot_table(north_table, values='count_north', index=['a_id', 'b_id'], aggfunc=np.sum)\n",
    "north_table = north_table.sort_values(('count_north'), ascending=False)\n",
    "\n",
    "south_table = pd.DataFrame.from_dict(south_table)\n",
    "south_table = south_table[(south_table[['count_south']] != 0).all(axis=1)]\n",
    "south_table = pd.pivot_table(south_table, values='count_south', index=['a_id', 'b_id'],aggfunc=np.sum)\n",
    "south_table = south_table.sort_values(('count_south'), ascending=False)\n",
    "\n",
    "east_table = pd.DataFrame.from_dict(east_table)\n",
    "east_table = east_table[(east_table[['count_east']] != 0).all(axis=1)]\n",
    "east_table = pd.pivot_table(east_table, values='count_east', index=['a_id', 'b_id'], aggfunc=np.sum)\n",
    "east_table = east_table.sort_values(('count_east'), ascending=False)\n",
    "\n",
    "west_table = pd.DataFrame.from_dict(west_table)\n",
    "west_table = west_table[(west_table[['count_west']] != 0).all(axis=1)]\n",
    "west_table = pd.pivot_table(west_table, values='count_west', index=['a_id', 'b_id'], aggfunc=np.sum)\n",
    "west_table = west_table.sort_values(('count_west'), ascending=False)\n",
    "\n",
    "print(\"Co Occurrence Tables Created. Time elapsed: {} seconds\".format(time.time()-time_start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "north_table.to_csv('north_table1.csv') #Remove 2 for orignal\n",
    "south_table.to_csv('south_table1.csv') \n",
    "east_table.to_csv('east_table1.csv') \n",
    "west_table.to_csv('west_table1.csv') \n",
    "\n",
    "north_table = pd.read_csv(\"north_table1.csv\") \n",
    "south_table = pd.read_csv(\"south_table1.csv\") \n",
    "east_table = pd.read_csv(\"east_table1.csv\") \n",
    "west_table = pd.read_csv(\"west_table1.csv\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using NPMI Formula: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Consistencies Added. Time elapsed: 132.7533130645752 seconds\n"
     ]
    }
   ],
   "source": [
    "if formula=='NPMI':\n",
    "    time_start = time.time()\n",
    "    north_table['north_consistency'] = 0 \n",
    "    total_count_north = north_table['count_north'].sum()\n",
    "    for i, j in north_table.iterrows(): \n",
    "        cooc_probability= north_table.loc[(north_table['a_id'] == j[0]) & (north_table['b_id'] == j[1]),'count_north'].sum() / total_count_north\n",
    "        marginal_a_id_probability= north_table.loc[north_table['a_id'] == j[0], 'count_north'].sum() / total_count_north\n",
    "        marginal_b_id_probability= north_table.loc[north_table['b_id'] == j[1], 'count_north'].sum() /total_count_north\n",
    "        consistency_north=float(np.log2(cooc_probability / (marginal_a_id_probability * marginal_b_id_probability))/np.log2(1 / cooc_probability))\n",
    "        north_table.loc[(north_table['a_id'] == j[0]) & (north_table['b_id'] == j[1]), 'north_consistency'] = consistency_north\n",
    "\n",
    "    south_table['south_consistency'] = 0 \n",
    "    total_count_south = south_table['count_south'].sum()\n",
    "    for i, j in south_table.iterrows(): \n",
    "        cooc_probability= south_table.loc[(south_table['a_id'] == j[0]) & (south_table['b_id'] == j[1]),'count_south'].sum() / total_count_south\n",
    "        marginal_a_id_probability= south_table.loc[south_table['a_id'] == j[0], 'count_south'].sum() / total_count_south\n",
    "        marginal_b_id_probability= south_table.loc[south_table['b_id'] == j[1], 'count_south'].sum() /total_count_south\n",
    "        consistency_south=float(np.log2(cooc_probability / (marginal_a_id_probability * marginal_b_id_probability))/np.log2(1 / cooc_probability))\n",
    "        south_table.loc[(south_table['a_id'] == j[0]) & (south_table['b_id'] == j[1]), 'south_consistency'] = consistency_south\n",
    "\n",
    "    east_table['east_consistency'] = 0 \n",
    "    total_count_east = east_table['count_east'].sum()\n",
    "    for i, j in east_table.iterrows(): \n",
    "        cooc_probability= east_table.loc[(east_table['a_id'] == j[0]) & (east_table['b_id'] == j[1]),'count_east'].sum() / total_count_east\n",
    "        marginal_a_id_probability= east_table.loc[east_table['a_id'] == j[0], 'count_east'].sum() / total_count_east\n",
    "        marginal_b_id_probability= east_table.loc[east_table['b_id'] == j[1], 'count_east'].sum() /total_count_east\n",
    "        consistency_east=float(np.log2(cooc_probability / (marginal_a_id_probability * marginal_b_id_probability))/np.log2(1 / cooc_probability))\n",
    "        east_table.loc[(east_table['a_id'] == j[0]) & (east_table['b_id'] == j[1]), 'east_consistency'] = consistency_east\n",
    "\n",
    "    west_table['west_consistency'] = 0 \n",
    "    total_count_west = west_table['count_west'].sum()\n",
    "    for i, j in west_table.iterrows(): \n",
    "        cooc_probability= west_table.loc[(west_table['a_id'] == j[0]) & (west_table['b_id'] == j[1]),'count_west'].sum() / total_count_west\n",
    "        marginal_a_id_probability= west_table.loc[west_table['a_id'] == j[0], 'count_west'].sum() / total_count_west\n",
    "        marginal_b_id_probability= west_table.loc[west_table['b_id'] == j[1], 'count_west'].sum() /total_count_west\n",
    "        consistency_west=float(np.log2(cooc_probability / (marginal_a_id_probability * marginal_b_id_probability))/np.log2(1 / cooc_probability))\n",
    "        west_table.loc[(west_table['a_id'] == j[0]) & (west_table['b_id'] == j[1]), 'west_consistency'] = consistency_west\n",
    "\n",
    "    print(\"Consistencies Added. Time elapsed: {} seconds\".format(time.time()-time_start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other Formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "if formula=='Other':\n",
    "    time_start = time.time()\n",
    "    north_table['north_consistency'] = 0 \n",
    "    for i, j in north_table.iterrows(): \n",
    "        plr=north_table.loc[north_table['a_id'] == j[0], 'count_north'].sum()\n",
    "        pll=north_table.loc[north_table['b_id'] == j[1], 'count_north'].sum()\n",
    "        pt=north_table.loc[(north_table['a_id'] == j[0]) & (north_table['b_id'] == j[1]),'count_north'].sum()\n",
    "        consistency=math.log(pt/(plr*pll))\n",
    "        north_table.loc[(north_table['a_id'] == j[0]) & (north_table['b_id'] == j[1]), 'north_consistency'] = consistency\n",
    "\n",
    "    south_table['south_consistency'] = 0 \n",
    "    for i, j in south_table.iterrows(): \n",
    "        plr=south_table.loc[south_table['a_id'] == j[0], 'count_south'].sum()\n",
    "        pll=south_table.loc[south_table['b_id'] == j[1], 'count_south'].sum()\n",
    "        pt=south_table.loc[(south_table['a_id'] == j[0]) & (south_table['b_id'] == j[1]),'count_south'].sum()\n",
    "        consistency=math.log(pt/(plr*pll))\n",
    "        south_table.loc[(south_table['a_id'] == j[0]) & (south_table['b_id'] == j[1]), 'south_consistency'] = consistency\n",
    "\n",
    "    east_table['east_consistency'] = 0 \n",
    "    for i, j in east_table.iterrows(): \n",
    "        plr=east_table.loc[east_table['a_id'] == j[0], 'count_east'].sum()\n",
    "        pll=east_table.loc[east_table['b_id'] == j[1], 'count_east'].sum()\n",
    "        pt=east_table.loc[(east_table['a_id'] == j[0]) & (east_table['b_id'] == j[1]),'count_east'].sum()\n",
    "        consistency=math.log(pt/(plr*pll))\n",
    "        east_table.loc[(east_table['a_id'] == j[0]) & (east_table['b_id'] == j[1]), 'east_consistency'] = consistency\n",
    "\n",
    "    west_table['west_consistency'] = 0 \n",
    "    for i, j in west_table.iterrows(): \n",
    "        plr=west_table.loc[west_table['a_id'] == j[0], 'count_west'].sum()\n",
    "        pll=west_table.loc[west_table['b_id'] == j[1], 'count_west'].sum()\n",
    "        pt=west_table.loc[(west_table['a_id'] == j[0]) & (west_table['b_id'] == j[1]),'count_west'].sum()\n",
    "        consistency=math.log(pt/(plr*pll))\n",
    "        west_table.loc[(west_table['a_id'] == j[0]) & (west_table['b_id'] == j[1]), 'west_consistency'] = consistency\n",
    "\n",
    "    print(\"Consistencies Added. Time elapsed: {} seconds\".format(time.time()-time_start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a_id</th>\n",
       "      <th>b_id</th>\n",
       "      <th>count_east</th>\n",
       "      <th>east_consistency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>7483.4</td>\n",
       "      <td>-0.005078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>980.3</td>\n",
       "      <td>0.010353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>882.5</td>\n",
       "      <td>-0.001891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>878.5</td>\n",
       "      <td>0.016848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "      <td>833.7</td>\n",
       "      <td>0.014526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11985</th>\n",
       "      <td>101</td>\n",
       "      <td>13</td>\n",
       "      <td>0.2</td>\n",
       "      <td>-0.055396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11986</th>\n",
       "      <td>128</td>\n",
       "      <td>137</td>\n",
       "      <td>0.2</td>\n",
       "      <td>-0.079107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11987</th>\n",
       "      <td>134</td>\n",
       "      <td>139</td>\n",
       "      <td>0.2</td>\n",
       "      <td>-0.088910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11988</th>\n",
       "      <td>122</td>\n",
       "      <td>37</td>\n",
       "      <td>0.2</td>\n",
       "      <td>-0.082641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11989</th>\n",
       "      <td>82</td>\n",
       "      <td>108</td>\n",
       "      <td>0.2</td>\n",
       "      <td>-0.066080</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11990 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       a_id  b_id  count_east  east_consistency\n",
       "0         2     2      7483.4         -0.005078\n",
       "1         2    18       980.3          0.010353\n",
       "2        18     2       882.5         -0.001891\n",
       "3         2    50       878.5          0.016848\n",
       "4        50     2       833.7          0.014526\n",
       "...     ...   ...         ...               ...\n",
       "11985   101    13         0.2         -0.055396\n",
       "11986   128   137         0.2         -0.079107\n",
       "11987   134   139         0.2         -0.088910\n",
       "11988   122    37         0.2         -0.082641\n",
       "11989    82   108         0.2         -0.066080\n",
       "\n",
       "[11990 rows x 4 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "east_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x1=north_table[\"north_consistency\"].plot.hist(bins=100)\n",
    "plt.savefig('northhist.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage 5 Completed Succesfully!\n"
     ]
    }
   ],
   "source": [
    "#OUTPUT----------------------------------Remove temp for final-----------------\n",
    "north_table.to_csv('north_table'+load_path+'temp.csv', index=False) \n",
    "south_table.to_csv('south_table'+load_path+'temp.csv', index=False) \n",
    "east_table.to_csv('east_table'+load_path+'temp.csv', index=False) \n",
    "west_table.to_csv('west_table'+load_path+'temp.csv', index=False) \n",
    "print(\"Stage 5 Completed Succesfully!\")\n",
    "#OUTPUT-----------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reloading Directional Tables\n",
    "north_table = pd.read_csv(\"north_table_final.csv\") \n",
    "south_table = pd.read_csv(\"south_table_final.csv\") \n",
    "east_table = pd.read_csv(\"east_table_final.csv\") \n",
    "west_table = pd.read_csv(\"west_table_final.csv\") "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
